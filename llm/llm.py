# llm/llm.py

import os
import requests
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

class LLM:
    def __init__(
        self,
        provider='openai',  # Default provider
        model=None,
        temperature=0.7,
        max_tokens=1500,
        top_p=0.9,
        frequency_penalty=0.0,
        presence_penalty=0.0,
        **kwargs
    ):
        """
        Initialize the specified LLM provider with default parameters.

        Parameters:
        - provider (str): Provider to use ("openai", "anthropic", "mistral", "cohere").
        - model (str): Model to use for text generation.
        - temperature (float): Controls randomness in output.
        - max_tokens (int): Maximum number of tokens to generate.
        - top_p (float): Nucleus sampling parameter to control diversity.
        - frequency_penalty (float): Penalizes new tokens based on frequency.
        - presence_penalty (float): Penalizes new tokens based on presence.
        - **kwargs: Additional provider-specific parameters.
        """
        # Validate parameters
        if not 0 <= temperature <= 1:
            raise ValueError("Temperature must be between 0 and 1")
        if not 0 <= top_p <= 1:
            raise ValueError("Top_p must be between 0 and 1")
        
        self.provider = provider.lower()
        self.model = model
        self.temperature = temperature
        self.max_tokens = max_tokens
        self.top_p = top_p
        self.frequency_penalty = frequency_penalty
        self.presence_penalty = presence_penalty
        self.options = kwargs

        # Provider-specific configuration
        if self.provider == "openai":
            self.api_key = os.getenv("OPENAI_API_KEY")
            self.url = "https://api.openai.com/v1/chat/completions"
            if not self.api_key:
                raise ValueError("OpenAI API key missing in environment variables.")

        elif self.provider == "anthropic":
            self.api_key = os.getenv("ANTHROPIC_API_KEY")
            self.url = "https://api.anthropic.com/v1/messages"
            if not self.api_key:
                raise ValueError("Anthropic API key missing in environment variables.")

        elif self.provider == "mistral":
            self.api_key = os.getenv("MISTRAL_API_KEY")
            self.url = "https://api.mistral.ai/v1/chat/completions"
            if not self.api_key:
                raise ValueError("Mistral API key missing in environment variables.")

        elif self.provider == "cohere":
            self.api_key = os.getenv("CO_API_KEY")
            self.url = "https://api.cohere.com/v2/chat"
            if not self.api_key:
                raise ValueError("Cohere API key missing in environment variables.")

        else:
            raise ValueError(f"Invalid provider: {provider}. Choose from 'openai', 'anthropic', 'mistral', or 'cohere'.")

    def generate(self, input_text):
        """
        Generate a response using the configured LLM provider.

        Parameters:
        - input_text (str): Input text to generate a response.

        Returns:
        - response_text (str): Response generated by the provider.
        """
        headers = {
            "Content-Type": "application/json",
            "Accept": "application/json"
        }

        if self.provider == "openai":
            headers["Authorization"] = f"Bearer {self.api_key}"
            payload = {
                "model": self.model,
                "messages": [{"role": "user", "content": input_text}],
                "temperature": self.temperature,
                "max_tokens": self.max_tokens,
                "top_p": self.top_p,
                "frequency_penalty": self.frequency_penalty,
                "presence_penalty": self.presence_penalty
            }
            payload.update(self.options)

            try:
                response = requests.post(self.url, headers=headers, json=payload)
                response.raise_for_status()
                data = response.json()
                return data["choices"][0]["message"]["content"].strip()
            except requests.exceptions.RequestException as e:
                return f"Error during OpenAI request: {e}"
            except KeyError:
                return "Error parsing OpenAI API response."

        elif self.provider == "anthropic":
            headers["x-api-key"] = self.api_key
            headers["anthropic-version"] = "2023-06-01"
            payload = {
                "model": self.model,
                "messages": [{"role": "user", "content": input_text}],
                "max_tokens": self.max_tokens,
                "temperature": self.temperature,
                "top_p": self.top_p
            }
            payload.update(self.options)

            try:
                response = requests.post(self.url, headers=headers, json=payload)
                response.raise_for_status()
                data = response.json()
                return data["content"][0]["text"].strip()
            except requests.exceptions.RequestException as e:
                return f"Error during Anthropic request: {e}"
            except KeyError:
                return "Error parsing Anthropic API response."

        elif self.provider == "mistral":
            headers["Authorization"] = f"Bearer {self.api_key}"
            payload = {
                "model": self.model,
                "messages": [{"role": "user", "content": input_text}],
                "temperature": self.temperature,
                "max_tokens": self.max_tokens,
                "top_p": self.top_p,
                "stream": self.options.get("stream", False),
                "safe_prompt": self.options.get("safe_prompt", False)
            }
            
            # Add optional parameters for Mistral
            optional_params = {
                "random_seed": self.options.get("random_seed"),
                "stop": self.options.get("stop"),
                "response_format": self.options.get("response_format"),
                "tools": self.options.get("tools"),
                "tool_choice": self.options.get("tool_choice", "auto")
            }
            payload.update({k: v for k, v in optional_params.items() if v is not None})

            try:
                response = requests.post(self.url, headers=headers, json=payload)
                response.raise_for_status()
                data = response.json()
                return data["choices"][0]["message"]["content"].strip()
            except requests.exceptions.RequestException as e:
                return f"Error during Mistral request: {e}"
            except KeyError:
                return "Error parsing Mistral API response."

        elif self.provider == "cohere":
            headers["Authorization"] = f"Bearer {self.api_key}"
            payload = {
                "model": self.model,
                "messages": [{
                    "role": "user",
                    "content": {
                        "type": "text",
                        "text": input_text
                    }
                }],
                "temperature": self.temperature,
                "max_tokens": self.max_tokens,
                "p": self.top_p  # Cohere uses 'p' instead of 'top_p'
            }

            # Add provider-specific optional parameters
            optional_params = {
                "stream": self.options.get("stream", False),
                "tools": self.options.get("tools"),
                "response_format": self.options.get("response_format"),
                "safety_mode": "CONTEXTUAL" if self.options.get("safe_prompt") else None,
                "frequency_penalty": self.options.get("frequency_penalty"),
                "presence_penalty": self.options.get("presence_penalty"),
                "stop_sequences": self.options.get("stop")
            }
            payload.update({k: v for k, v in optional_params.items() if v is not None})

            try:
                response = requests.post(self.url, headers=headers, json=payload)
                response.raise_for_status()
                data = response.json()
                return data["message"]["content"][0]["text"].strip()
            except requests.exceptions.RequestException as e:
                return f"Error during Cohere request: {e}"
            except KeyError:
                return "Error parsing Cohere API response."

        return "Invalid provider."
